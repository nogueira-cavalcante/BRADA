{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import BR_ML as brada\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0.1\n"
     ]
    }
   ],
   "source": [
    "print(brada.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['No', 'year', 'month', 'day', 'hour', 'season', 'PM_Dongsi',\n",
       "       'PM_Dongsihuan', 'PM_Nongzhanguan', 'PM_US Post', 'DEWP', 'HUMI',\n",
       "       'PRES', 'TEMP', 'cbwd', 'Iws', 'precipitation', 'Iprec'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pequim = pd.read_csv('datasets/BeijingPM20100101_20151231.csv')\n",
    "pequim.dropna(inplace=True)\n",
    "\n",
    "pequim['date'] = pequim['year'].astype(str) + '-' + pequim['month'].astype(str) + '-' + pequim['day'].astype(str)\n",
    "pequim.drop_duplicates(subset='date', inplace=True)\n",
    "pequim['date'] = pd.to_datetime(pequim['date'])\n",
    "pequim.sort_values('date', inplace=True)\n",
    "pequim.set_index('date', inplace=True)\n",
    "pequim.index = pd.DatetimeIndex(pequim.index).to_period('D')\n",
    "\n",
    "pequim.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['User_ID', 'Product_ID', 'Gender', 'Age', 'Occupation', 'City_Category',\n",
       "       'Stay_In_Current_City_Years', 'Marital_Status', 'Product_Category_1',\n",
       "       'Product_Category_2', 'Product_Category_3', 'Purchase'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "black_friday = pd.read_csv('datasets/BlackFriday.csv')\n",
    "black_friday.columns                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume'], dtype='object')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fb = pd.read_csv('datasets/FB.csv')\n",
    "fb.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb['Date'] = pd.to_datetime(fb['Date'])\n",
    "fb = fb.set_index('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-11-16</th>\n",
       "      <td>106.839996</td>\n",
       "      <td>107.870003</td>\n",
       "      <td>106.620003</td>\n",
       "      <td>107.320000</td>\n",
       "      <td>107.320000</td>\n",
       "      <td>22129600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-11-23</th>\n",
       "      <td>107.190002</td>\n",
       "      <td>107.470001</td>\n",
       "      <td>104.389999</td>\n",
       "      <td>105.449997</td>\n",
       "      <td>105.449997</td>\n",
       "      <td>64538400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-11-30</th>\n",
       "      <td>105.839996</td>\n",
       "      <td>107.919998</td>\n",
       "      <td>103.349998</td>\n",
       "      <td>106.180000</td>\n",
       "      <td>106.180000</td>\n",
       "      <td>112055400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-07</th>\n",
       "      <td>106.480003</td>\n",
       "      <td>106.910004</td>\n",
       "      <td>101.910004</td>\n",
       "      <td>102.120003</td>\n",
       "      <td>102.120003</td>\n",
       "      <td>103276000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-14</th>\n",
       "      <td>102.290001</td>\n",
       "      <td>107.750000</td>\n",
       "      <td>101.459999</td>\n",
       "      <td>104.040001</td>\n",
       "      <td>104.040001</td>\n",
       "      <td>126762800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open        High         Low       Close   Adj Close  \\\n",
       "Date                                                                     \n",
       "2015-11-16  106.839996  107.870003  106.620003  107.320000  107.320000   \n",
       "2015-11-23  107.190002  107.470001  104.389999  105.449997  105.449997   \n",
       "2015-11-30  105.839996  107.919998  103.349998  106.180000  106.180000   \n",
       "2015-12-07  106.480003  106.910004  101.910004  102.120003  102.120003   \n",
       "2015-12-14  102.290001  107.750000  101.459999  104.040001  104.040001   \n",
       "\n",
       "               Volume  \n",
       "Date                   \n",
       "2015-11-16   22129600  \n",
       "2015-11-23   64538400  \n",
       "2015-11-30  112055400  \n",
       "2015-12-07  103276000  \n",
       "2015-12-14  126762800  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.06839996e+02, 1.07870003e+02, 1.06620003e+02, 1.07320000e+02,\n",
       "        1.07320000e+02, 2.21296000e+07],\n",
       "       [1.07190002e+02, 1.07470001e+02, 1.04389999e+02, 1.05449997e+02,\n",
       "        1.05449997e+02, 6.45384000e+07],\n",
       "       [1.05839996e+02, 1.07919998e+02, 1.03349998e+02, 1.06180000e+02,\n",
       "        1.06180000e+02, 1.12055400e+08],\n",
       "       ...,\n",
       "       [2.89869995e+02, 2.92579987e+02, 2.64000000e+02, 2.76950012e+02,\n",
       "        2.76950012e+02, 9.24331000e+07],\n",
       "       [2.75049988e+02, 2.79410004e+02, 2.69190002e+02, 2.69700012e+02,\n",
       "        2.69700012e+02, 7.12420000e+07],\n",
       "       [2.72559998e+02, 2.73000000e+02, 2.69410004e+02, 2.69700012e+02,\n",
       "        2.69700012e+02, 1.68915160e+07]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.inverse_transform(pipe.fit_transform(fb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.43040999, -1.45118347, -1.38574116, -1.42453699, -1.42453699,\n",
       "        -1.57788254],\n",
       "       [-1.42220805, -1.46008108, -1.44029388, -1.46794446, -1.46794446,\n",
       "        -0.76482576],\n",
       "       [-1.45384368, -1.45007139, -1.46573549, -1.45099925, -1.45099925,\n",
       "         0.14616487],\n",
       "       ...,\n",
       "       [ 2.85865984,  2.65748923,  2.46425523,  2.51300205,  2.51300205,\n",
       "        -0.23003168],\n",
       "       [ 2.51137226,  2.36453728,  2.59121856,  2.34471132,  2.34471132,\n",
       "        -0.63630508],\n",
       "       [ 2.45302259,  2.22195371,  2.59660048,  2.34471132,  2.34471132,\n",
       "        -1.67830651]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit_transform(fb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = pd.DataFrame(data = scaler.fit_transform(fb), columns=fb.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.052224</td>\n",
       "      <td>0.047435</td>\n",
       "      <td>0.094900</td>\n",
       "      <td>0.062157</td>\n",
       "      <td>0.062157</td>\n",
       "      <td>0.012040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.053997</td>\n",
       "      <td>0.045499</td>\n",
       "      <td>0.082632</td>\n",
       "      <td>0.052745</td>\n",
       "      <td>0.052745</td>\n",
       "      <td>0.109520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.047158</td>\n",
       "      <td>0.047677</td>\n",
       "      <td>0.076910</td>\n",
       "      <td>0.056420</td>\n",
       "      <td>0.056420</td>\n",
       "      <td>0.218741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.050400</td>\n",
       "      <td>0.042788</td>\n",
       "      <td>0.068988</td>\n",
       "      <td>0.035986</td>\n",
       "      <td>0.035986</td>\n",
       "      <td>0.198561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.029176</td>\n",
       "      <td>0.046854</td>\n",
       "      <td>0.066513</td>\n",
       "      <td>0.045649</td>\n",
       "      <td>0.045649</td>\n",
       "      <td>0.252548</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Open      High       Low     Close  Adj Close    Volume\n",
       "0  0.052224  0.047435  0.094900  0.062157   0.062157  0.012040\n",
       "1  0.053997  0.045499  0.082632  0.052745   0.052745  0.109520\n",
       "2  0.047158  0.047677  0.076910  0.056420   0.056420  0.218741\n",
       "3  0.050400  0.042788  0.068988  0.035986   0.035986  0.198561\n",
       "4  0.029176  0.046854  0.066513  0.045649   0.045649  0.252548"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaling(df, scaling_methods, kwargs=None):\n",
    "    \n",
    "    import pandas as pd\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    \n",
    "    list_scaler = []\n",
    "    for i in range(len(scaling_methods)):\n",
    "        \n",
    "        scaling_method = scaling_methods[i]\n",
    "        if kwargs is None:\n",
    "            kwargs_method = dict{}\n",
    "        else:\n",
    "            kwargs_method = kwargs[i]\n",
    "        \n",
    "        if scaling_method == 'min_max':\n",
    "            from sklearn.preprocessing import MinMaxScaler\n",
    "            list_scaler.append(('min_max', MinMaxScaler(kwargs_method)))\n",
    "            \n",
    "        elif scaling_method == 'max_abs':\n",
    "            from sklearn.preprocessing import MaxAbsScaler\n",
    "            list_scaler.append(('max_max', MaxAbsScaler(kwargs_method)))\n",
    "            \n",
    "        elif scaling_method == 'standard':\n",
    "            from sklearn.preprocessing import StandardScaler\n",
    "            list_scaler.append(('standard', StandardScaler(kwargs_method)))\n",
    "            \n",
    "        elif scaling_method == 'robust':\n",
    "            from sklearn.preprocessing import RobustScaler\n",
    "            list_scaler.append(('robust', RobustScaler(kwargs_method)))\n",
    "            \n",
    "        elif scaling_method == 'normalizer':\n",
    "            from sklearn.preprocessing import Normalizer\n",
    "            list_scaler.append(('normalizer', Normalizer(kwargs_method)))\n",
    "            \n",
    "        elif scaling_method == 'quantile':\n",
    "            from sklearn.preprocessing import QuantileTransformer\n",
    "            list_scaler.append(('quantile', QuantileTransformer(kwargs_method)))\n",
    "            \n",
    "        elif scaling_method == 'power_transform':\n",
    "            from sklearn.preprocessing import PowerTransformer\n",
    "            list_scaler.append(('power_transform', PowerTransformer(kwargs_method)))\n",
    "            \n",
    "    \n",
    "    pipe = Pipeline(list_scaler)\n",
    "    \n",
    "    df_temp = pipe.fit_transform(df)\n",
    "    df_temp = pd.DataFrame(data=df_temp, columns=df.columns)\n",
    "    \n",
    "    return df_temp, pipe"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
